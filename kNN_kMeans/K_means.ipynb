{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1000_image = np.load(r\"F:/Fall 2019/stat 479-ML/Project_Group_7/GITHUB/sample_1000_image.npy\",allow_pickle=True)\n",
    "sample_1000_label = np.load(r\"F:/Fall 2019/stat 479-ML/Project_Group_7/GITHUB/sample_1000_label.npy\",allow_pickle=True)\n",
    "\n",
    "label_map = open(r\"F:/Fall 2019/stat 479-ML/Project_Group_7/GITHUB/stat-479-project/DataPrep/label_map.txt\")\n",
    "label_map = ast.literal_eval(label_map.read())\n",
    "\n",
    "sample_1000_label = list(sample_1000_label.flatten())\n",
    "sample_1000_label = list(label_map.get(k, \"\") for k in sample_1000_label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=sample_1000_image/255\n",
    "pca = PCA(n_components=256)\n",
    "\n",
    "X_pca = pca.fit_transform(X)\n",
    "print(X_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = pca.explained_variance_ratio_ #calculate variance ratios\n",
    "var=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=3)*100)\n",
    "print(np.argmax(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylabel('% Variance Explained')\n",
    "plt.xlabel('# of Features')\n",
    "plt.title('PCA Analysis')\n",
    "plt.ylim(30,100.5)\n",
    "plt.style.context('seaborn-whitegrid')\n",
    "\n",
    "plt.plot(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meanVals = np.mean(X, axis=0)\n",
    "# DataAdjust = X-meanVals      \n",
    "# cov_mat = np.cov(DataAdjust.astype(float).T)\n",
    "\n",
    "# eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "# print('\\nEigenvalues \\n%s' %eig_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(X,X,c='white',marker='o',edgecolor='black',s=50)\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import time\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction =[]\n",
    "distortions = []\n",
    "t0 = time.time()\n",
    "\n",
    "for i in range(1, 351, 50):\n",
    "    print(i)\n",
    "    km = MiniBatchKMeans(init='k-means++', n_clusters=i, batch_size=10000, n_init=10, max_iter=300)\n",
    "    prediction.append(km.fit_predict(X_pca))\n",
    "    distortions.append(km.inertia_)\n",
    "\n",
    "    \n",
    "km = MiniBatchKMeans(init='k-means++', n_clusters=345, batch_size=10000, n_init=10, max_iter=300)\n",
    "prediction.append(km.fit_predict(X_pca))\n",
    "distortions.append(km.inertia_)\n",
    "    \n",
    "t_mini_batch = time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t_mini_batch)\n",
    "\n",
    "plt.plot( distortions, marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Distortion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_kmeans=list(prediction[5])\n",
    "y_category = np.array(sample_1000_label)\n",
    "clusters=set(y_kmeans)\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_index = []\n",
    "for cluster in clusters:\n",
    "    indices = [i for i, x in enumerate(y_kmeans) if x == cluster]\n",
    "    cluster_index.append(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_cluster=[]\n",
    "for index in cluster_index:\n",
    "    category_cluster.append(y_category[index]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for new_category in category_cluster:\n",
    "#     print(new_category)\n",
    "    c = Counter(new_category)\n",
    "    print(c.most_common(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###accuracy \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
