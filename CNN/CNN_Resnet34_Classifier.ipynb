{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Architecture\n",
    "NUM_FEATURES = 28*28\n",
    "NUM_CLASSES = 345\n",
    "\n",
    "# Other\n",
    "DEVICE = \"cuda:0\"\n",
    "GRAYSCALE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "images = np.load(\"Data/sample_1000_image.npy\")\n",
    "labels = np.load(\"Data/sample_1000_label.npy\")\n",
    "\n",
    "# Normalize image data.  0-255 to 0-1\n",
    "images = images / 255\n",
    "df = pd.DataFrame(np.concatenate((images, labels), axis=1))\n",
    "\n",
    "# Rename the last column as \"label\"\n",
    "df.rename(columns={784:\"label\"}, inplace=True)\n",
    "\n",
    "# Convert label column to integer type\n",
    "df['label'] = df['label'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get \"img\" data frame and \"lbl\" series from the df\n",
    "img = df.iloc[:, 0:-1]\n",
    "lbl = df['label']\n",
    "# Split into train, validation and test set\n",
    "x_train1, x_test, y_train1, y_test = train_test_split(img, lbl, test_size = 0.10, random_state = 123, stratify = lbl)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train1, y_train1, test_size = 0.2, random_state = 123, stratify = y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(248400, 784)\n",
      "(62100, 784)\n",
      "(34500, 784)\n",
      "(248400,)\n",
      "(62100,)\n",
      "(34500,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_valid.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe to tensor\n",
    "x_train = torch.tensor(x_train.values)\n",
    "y_train = torch.tensor(y_train.values)\n",
    "\n",
    "x_valid = torch.tensor(x_valid.values)\n",
    "y_valid = torch.tensor(y_valid.values)\n",
    "\n",
    "x_test = torch.tensor(x_test.values)\n",
    "y_test = torch.tensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape all tensors to the size of (length, 1, 28, 28)\n",
    "x_train = x_train.reshape((-1, 1, 28, 28))\n",
    "x_valid = x_valid.reshape((-1, 1, 28, 28))\n",
    "x_test = x_test.reshape((-1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "valid_dataset = TensorDataset(x_valid, y_valid)\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=True, num_workers=4)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         shuffle=False, num_workers=4)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([128, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch index: 0 | Batch size: 128\n",
      "Epoch: 2 | Batch index: 0 | Batch size: 128\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(DEVICE if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(0)\n",
    "\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', y.size()[0])\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes, grayscale):\n",
    "        self.inplanes = 64\n",
    "        if grayscale:\n",
    "            in_dim = 1\n",
    "        else:\n",
    "            in_dim = 3\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, (2. / n)**.5)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        # because MNIST is already 1x1 here:\n",
    "        # disable avg pooling\n",
    "        #x = self.avgpool(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.fc(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "\n",
    "\n",
    "\n",
    "def resnet34(num_classes):\n",
    "    \"\"\"Constructs a ResNet-34 model.\"\"\"\n",
    "    model = ResNet(block=BasicBlock, \n",
    "                   layers=[3, 4, 6, 3],\n",
    "                   num_classes=NUM_CLASSES,\n",
    "                   grayscale=GRAYSCALE)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = resnet34(NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sizes(self, input, output):\n",
    "\n",
    "    print('Inside ' + self.__class__.__name__ + ' forward')\n",
    "    print('input size:', input[0].size())\n",
    "    print('output size:', output.data.size())\n",
    "\n",
    "    \n",
    "## Debugging\n",
    "\n",
    "\n",
    "# model.features[0].register_forward_hook(print_sizes)\n",
    "# model.features[1].register_forward_hook(print_sizes)\n",
    "# model.features[2].register_forward_hook(print_sizes)\n",
    "# model.features[3].register_forward_hook(print_sizes)\n",
    "\n",
    "# model.classifier[0].register_forward_hook(print_sizes)\n",
    "# model.classifier[1].register_forward_hook(print_sizes)\n",
    "# model.classifier[2].register_forward_hook(print_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "        \n",
    "        features = features.float()\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 0000/1941 | Cost: 6.1763\n",
      "Epoch: 001/010 | Batch 0500/1941 | Cost: 3.2900\n",
      "Epoch: 001/010 | Batch 1000/1941 | Cost: 2.9493\n",
      "Epoch: 001/010 | Batch 1500/1941 | Cost: 2.5501\n",
      "Epoch: 001/010 | Train: 44.230% | Validation: 43.016%\n",
      "Time elapsed: 3.79 min\n",
      "Epoch: 002/010 | Batch 0000/1941 | Cost: 2.2421\n",
      "Epoch: 002/010 | Batch 0500/1941 | Cost: 2.1930\n",
      "Epoch: 002/010 | Batch 1000/1941 | Cost: 2.1541\n",
      "Epoch: 002/010 | Batch 1500/1941 | Cost: 1.8415\n",
      "Epoch: 002/010 | Train: 51.058% | Validation: 48.928%\n",
      "Time elapsed: 7.92 min\n",
      "Epoch: 003/010 | Batch 0000/1941 | Cost: 1.4746\n",
      "Epoch: 003/010 | Batch 0500/1941 | Cost: 1.6010\n",
      "Epoch: 003/010 | Batch 1000/1941 | Cost: 1.8388\n",
      "Epoch: 003/010 | Batch 1500/1941 | Cost: 1.6597\n",
      "Epoch: 003/010 | Train: 58.325% | Validation: 54.372%\n",
      "Time elapsed: 12.25 min\n",
      "Epoch: 004/010 | Batch 0000/1941 | Cost: 1.4683\n",
      "Epoch: 004/010 | Batch 0500/1941 | Cost: 2.2620\n",
      "Epoch: 004/010 | Batch 1000/1941 | Cost: 1.3325\n",
      "Epoch: 004/010 | Batch 1500/1941 | Cost: 2.0776\n",
      "Epoch: 004/010 | Train: 61.960% | Validation: 56.816%\n",
      "Time elapsed: 16.68 min\n",
      "Epoch: 005/010 | Batch 0000/1941 | Cost: 1.4538\n",
      "Epoch: 005/010 | Batch 0500/1941 | Cost: 1.4088\n",
      "Epoch: 005/010 | Batch 1000/1941 | Cost: 1.4545\n",
      "Epoch: 005/010 | Batch 1500/1941 | Cost: 1.3597\n",
      "Epoch: 005/010 | Train: 63.203% | Validation: 56.791%\n",
      "Time elapsed: 21.18 min\n",
      "Epoch: 006/010 | Batch 0000/1941 | Cost: 1.3022\n",
      "Epoch: 006/010 | Batch 0500/1941 | Cost: 1.3091\n",
      "Epoch: 006/010 | Batch 1000/1941 | Cost: 1.1539\n",
      "Epoch: 006/010 | Batch 1500/1941 | Cost: 1.0577\n",
      "Epoch: 006/010 | Train: 66.780% | Validation: 58.723%\n",
      "Time elapsed: 25.79 min\n",
      "Epoch: 007/010 | Batch 0000/1941 | Cost: 1.3535\n",
      "Epoch: 007/010 | Batch 0500/1941 | Cost: 1.2723\n",
      "Epoch: 007/010 | Batch 1000/1941 | Cost: 1.5903\n",
      "Epoch: 007/010 | Batch 1500/1941 | Cost: 1.3430\n",
      "Epoch: 007/010 | Train: 69.786% | Validation: 59.143%\n",
      "Time elapsed: 30.40 min\n",
      "Epoch: 008/010 | Batch 0000/1941 | Cost: 1.1526\n",
      "Epoch: 008/010 | Batch 0500/1941 | Cost: 1.1714\n",
      "Epoch: 008/010 | Batch 1000/1941 | Cost: 1.3752\n",
      "Epoch: 008/010 | Batch 1500/1941 | Cost: 1.3167\n",
      "Epoch: 008/010 | Train: 72.872% | Validation: 60.174%\n",
      "Time elapsed: 35.06 min\n",
      "Epoch: 009/010 | Batch 0000/1941 | Cost: 0.8813\n",
      "Epoch: 009/010 | Batch 0500/1941 | Cost: 1.1343\n",
      "Epoch: 009/010 | Batch 1000/1941 | Cost: 1.0141\n",
      "Epoch: 009/010 | Batch 1500/1941 | Cost: 0.9639\n",
      "Epoch: 009/010 | Train: 75.830% | Validation: 60.296%\n",
      "Time elapsed: 39.70 min\n",
      "Epoch: 010/010 | Batch 0000/1941 | Cost: 1.0316\n",
      "Epoch: 010/010 | Batch 0500/1941 | Cost: 0.9552\n",
      "Epoch: 010/010 | Batch 1000/1941 | Cost: 0.8708\n",
      "Epoch: 010/010 | Batch 1500/1941 | Cost: 0.8492\n",
      "Epoch: 010/010 | Train: 77.979% | Validation: 59.966%\n",
      "Time elapsed: 44.40 min\n",
      "Total Training Time: 44.40 min\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.float()\n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 500:\n",
    "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "                   %(epoch+1, NUM_EPOCHS, batch_idx, \n",
    "                     len(train_loader), cost))\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        print('Epoch: %03d/%03d | Train: %.3f%% | Validation: %.3f%%' % (\n",
    "              epoch+1, NUM_EPOCHS, \n",
    "              compute_accuracy(model, train_loader, device=DEVICE),\n",
    "              compute_accuracy(model, valid_loader, device=DEVICE) ))\n",
    "        \n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 59.96%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy after 10 epochs\n",
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch]",
   "language": "python",
   "name": "conda-env-.conda-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
